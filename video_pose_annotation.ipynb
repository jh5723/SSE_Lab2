{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jh5723/SSE_Lab2/blob/main/video_pose_annotation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q--F8iNMBcLr"
      },
      "source": [
        "# Install dependencies\n",
        "Clone and import a stable version of the easy_ViTPose repository for a PyTorch implementation of the ViTPose model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tGl9x1d-xgy7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd78999f-fa67-4ccc-ff02-5ea83ec1bdb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'easy_ViTPose'...\n",
            "remote: Enumerating objects: 924, done.\u001b[K\n",
            "remote: Counting objects: 100% (259/259), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 924 (delta 244), reused 202 (delta 202), pack-reused 665 (from 1)\u001b[K\n",
            "Receiving objects: 100% (924/924), 8.60 MiB | 5.81 MiB/s, done.\n",
            "Resolving deltas: 100% (568/568), done.\n",
            "/content/easy_ViTPose\n",
            "Fetching origin\n",
            "Note: switching to '9ca694a982c1f6097e8ebf14ae7c12526da89ef0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 9ca694a fix installation\n",
            "\u001b[33mcommit 9ca694a982c1f6097e8ebf14ae7c12526da89ef0\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD\u001b[m\u001b[33m)\u001b[m\n",
            "Author: JunkyByte <adriano.donninelli@hotmail.it>\n",
            "Date:   Fri Feb 16 15:30:34 2024 +0100\n",
            "\n",
            "    fix installation\n",
            "Collecting certifi==2023.7.22 (from -r requirements.txt (line 1))\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting charset-normalizer==3.2.0 (from -r requirements.txt (line 2))\n",
            "  Downloading charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting coloredlogs==15.0.1 (from -r requirements.txt (line 3))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting contourpy==1.1.1 (from -r requirements.txt (line 4))\n",
            "  Downloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting cycler==0.11.0 (from -r requirements.txt (line 5))\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting ffmpeg==1.4 (from -r requirements.txt (line 6))\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting filelock==3.12.4 (from -r requirements.txt (line 7))\n",
            "  Downloading filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting filterpy==1.4.5 (from -r requirements.txt (line 8))\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatbuffers==23.5.26 (from -r requirements.txt (line 9))\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting fonttools==4.43.0 (from -r requirements.txt (line 10))\n",
            "  Downloading fonttools-4.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.9/151.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly==10.0 (from -r requirements.txt (line 11))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting idna==3.4 (from -r requirements.txt (line 12))\n",
            "  Downloading idna-3.4-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting imageio==2.31.3 (from -r requirements.txt (line 13))\n",
            "  Downloading imageio-2.31.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting importlib-resources==6.1.0 (from -r requirements.txt (line 14))\n",
            "  Downloading importlib_resources-6.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: jinja2>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (3.1.4)\n",
            "Requirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (1.4.5)\n",
            "Collecting lazy_loader==0.3 (from -r requirements.txt (line 17))\n",
            "  Downloading lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting MarkupSafe==2.1.3 (from -r requirements.txt (line 18))\n",
            "  Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting matplotlib==3.8.0 (from -r requirements.txt (line 19))\n",
            "  Downloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (1.3.0)\n",
            "Collecting networkx==3.1 (from -r requirements.txt (line 21))\n",
            "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting numpy==1.26.0 (from -r requirements.txt (line 22))\n",
            "  Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx==1.14.1 (from -r requirements.txt (line 23))\n",
            "  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting onnxruntime==1.16.0 (from -r requirements.txt (line 24))\n",
            "  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting opencv-python==4.8.0.76 (from -r requirements.txt (line 25))\n",
            "  Downloading opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting packaging==23.1 (from -r requirements.txt (line 26))\n",
            "  Downloading packaging-23.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pandas==2.1.1 (from -r requirements.txt (line 27))\n",
            "  Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting Pillow>=10.2.0 (from -r requirements.txt (line 28))\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting protobuf==4.24.3 (from -r requirements.txt (line 29))\n",
            "  Downloading protobuf-4.24.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
            "Requirement already satisfied: psutil==5.9.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo==9.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (9.0.0)\n",
            "Collecting pyparsing==3.1.1 (from -r requirements.txt (line 32))\n",
            "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (2.8.2)\n",
            "Collecting pytz==2023.3.post1 (from -r requirements.txt (line 34))\n",
            "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting PyWavelets==1.4.1 (from -r requirements.txt (line 35))\n",
            "  Downloading PyWavelets-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting PyYAML==6.0.1 (from -r requirements.txt (line 36))\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting requests==2.31.0 (from -r requirements.txt (line 37))\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting scikit-image==0.21.0 (from -r requirements.txt (line 38))\n",
            "  Downloading scikit_image-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting scipy==1.11.2 (from -r requirements.txt (line 39))\n",
            "  Downloading scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seaborn==0.12.2 (from -r requirements.txt (line 40))\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (1.16.0)\n",
            "Collecting sympy==1.12 (from -r requirements.txt (line 42))\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tifffile==2023.9.18 (from -r requirements.txt (line 43))\n",
            "  Downloading tifffile-2023.9.18-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting tqdm==4.66.1 (from -r requirements.txt (line 44))\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions==4.8.0 (from -r requirements.txt (line 45))\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tzdata==2023.3 (from -r requirements.txt (line 46))\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting ultralytics==8.0.184 (from -r requirements.txt (line 47))\n",
            "  Downloading ultralytics-8.0.184-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: urllib3>=2.0.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 48)) (2.0.7)\n",
            "Collecting zipp==3.17.0 (from -r requirements.txt (line 49))\n",
            "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.184->-r requirements.txt (line 47)) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.184->-r requirements.txt (line 47)) (0.19.0+cu121)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.0.184->-r requirements.txt (line 47)) (2024.6.1)\n",
            "Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
            "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Downloading fonttools-4.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imageio-2.31.3-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.0/313.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.1.0-py3-none-any.whl (33 kB)\n",
            "Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
            "Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m123.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.24.3-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyWavelets-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_image-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tifffile-2023.9.18-py3-none-any.whl (222 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.1/222.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.0.184-py3-none-any.whl (618 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.0/618.0 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
            "Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ffmpeg, filterpy\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=8d36759364404f31a39464892e1bfc999589018b0cb83dd469bd05101cc412a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110459 sha256=5ea86b5a2233b9288604c9848596b8a52f239aa7d045c3b00f1d3c7693000ee2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built ffmpeg filterpy\n",
            "Installing collected packages: pytz, flatbuffers, ffmpeg, zipp, tzdata, typing_extensions, tqdm, sympy, PyYAML, pyparsing, protobuf, Pillow, packaging, numpy, networkx, MarkupSafe, lazy_loader, importlib-resources, idna, humanfriendly, fonttools, filelock, cycler, charset-normalizer, certifi, tifffile, scipy, requests, PyWavelets, pandas, opencv-python, onnx, imageio, contourpy, coloredlogs, scikit-image, onnxruntime, matplotlib, seaborn, filterpy, ultralytics\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2024.1\n",
            "    Uninstalling pytz-2024.1:\n",
            "      Successfully uninstalled pytz-2024.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.3.25\n",
            "    Uninstalling flatbuffers-24.3.25:\n",
            "      Successfully uninstalled flatbuffers-24.3.25\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.20.1\n",
            "    Uninstalling zipp-3.20.1:\n",
            "      Successfully uninstalled zipp-3.20.1\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2024.1\n",
            "    Uninstalling tzdata-2024.1:\n",
            "      Successfully uninstalled tzdata-2024.1\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.5\n",
            "    Uninstalling tqdm-4.66.5:\n",
            "      Successfully uninstalled tqdm-4.66.5\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.2\n",
            "    Uninstalling sympy-1.13.2:\n",
            "      Successfully uninstalled sympy-1.13.2\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.4\n",
            "    Uninstalling pyparsing-3.1.4:\n",
            "      Successfully uninstalled pyparsing-3.1.4\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: lazy_loader\n",
            "    Found existing installation: lazy_loader 0.4\n",
            "    Uninstalling lazy_loader-0.4:\n",
            "      Successfully uninstalled lazy_loader-0.4\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib_resources 6.4.4\n",
            "    Uninstalling importlib_resources-6.4.4:\n",
            "      Successfully uninstalled importlib_resources-6.4.4\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.8\n",
            "    Uninstalling idna-3.8:\n",
            "      Successfully uninstalled idna-3.8\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.53.1\n",
            "    Uninstalling fonttools-4.53.1:\n",
            "      Successfully uninstalled fonttools-4.53.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.15.4\n",
            "    Uninstalling filelock-3.15.4:\n",
            "      Successfully uninstalled filelock-3.15.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.7.4\n",
            "    Uninstalling certifi-2024.7.4:\n",
            "      Successfully uninstalled certifi-2024.7.4\n",
            "  Attempting uninstall: tifffile\n",
            "    Found existing installation: tifffile 2024.8.24\n",
            "    Uninstalling tifffile-2024.8.24:\n",
            "      Successfully uninstalled tifffile-2024.8.24\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.10.0.84\n",
            "    Uninstalling opencv-python-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-4.10.0.84\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.34.2\n",
            "    Uninstalling imageio-2.34.2:\n",
            "      Successfully uninstalled imageio-2.34.2\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.2.1\n",
            "    Uninstalling contourpy-1.2.1:\n",
            "      Successfully uninstalled contourpy-1.2.1\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.23.2\n",
            "    Uninstalling scikit-image-0.23.2:\n",
            "      Successfully uninstalled scikit-image-0.23.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.13.1\n",
            "    Uninstalling seaborn-0.13.1:\n",
            "      Successfully uninstalled seaborn-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.13 requires typing-extensions>=4.9.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "albumentations 1.4.14 requires typing-extensions>=4.9.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "bokeh 3.4.3 requires contourpy>=1.2, but you have contourpy 1.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.24.3 which is incompatible.\n",
            "typeguard 4.3.0 requires typing-extensions>=4.10.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.3 Pillow-10.4.0 PyWavelets-1.4.1 PyYAML-6.0.1 certifi-2023.7.22 charset-normalizer-3.2.0 coloredlogs-15.0.1 contourpy-1.1.1 cycler-0.11.0 ffmpeg-1.4 filelock-3.12.4 filterpy-1.4.5 flatbuffers-23.5.26 fonttools-4.43.0 humanfriendly-10.0 idna-3.4 imageio-2.31.3 importlib-resources-6.1.0 lazy_loader-0.3 matplotlib-3.8.0 networkx-3.1 numpy-1.26.0 onnx-1.14.1 onnxruntime-1.16.0 opencv-python-4.8.0.76 packaging-23.1 pandas-2.1.1 protobuf-4.24.3 pyparsing-3.1.1 pytz-2023.3.post1 requests-2.31.0 scikit-image-0.21.0 scipy-1.11.2 seaborn-0.12.2 sympy-1.12 tifffile-2023.9.18 tqdm-4.66.1 typing_extensions-4.8.0 tzdata-2023.3 ultralytics-8.0.184 zipp-3.17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "cycler",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "c0a71f5f56d8481181cacb8f5ca79d39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/easy_ViTPose\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: easy_ViTPose\n",
            "  Running setup.py develop for easy_ViTPose\n",
            "Successfully installed easy_ViTPose-1.1\n",
            "\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JunkyByte/easy_ViTPose.git\n",
        "%cd easy_ViTPose\n",
        "!git fetch --all\n",
        "!git checkout 9ca694a982c1f6097e8ebf14ae7c12526da89ef0\n",
        "!git log -1\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e .\n",
        "!pip install ipywidgets\n",
        "import sys\n",
        "sys.path.append('/content/easy_ViTPose')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkO9OUGOFZKp",
        "outputId": "a46c5884-e22d-4409-91bc-8f235bc63677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/my_drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/my_drive') # force_remount=True if failing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2geQtFvbuv3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f96c7a-93ca-4a1f-afa7-3af094019db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/my_drive/MyDrive/easy_ViTPose\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer==3.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: coloredlogs==15.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (15.0.1)\n",
            "Requirement already satisfied: contourpy==1.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.1.1)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: ffmpeg==1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.4)\n",
            "Requirement already satisfied: filelock==3.12.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.12.4)\n",
            "Requirement already satisfied: filterpy==1.4.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.4.5)\n",
            "Requirement already satisfied: flatbuffers==23.5.26 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (23.5.26)\n",
            "Requirement already satisfied: fonttools==4.43.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.43.0)\n",
            "Requirement already satisfied: humanfriendly==10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (10.0)\n",
            "Requirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: imageio==2.31.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.31.3)\n",
            "Requirement already satisfied: importlib-resources==6.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (6.1.0)\n",
            "Requirement already satisfied: jinja2>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (3.1.4)\n",
            "Requirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (1.4.5)\n",
            "Requirement already satisfied: lazy_loader==0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.3)\n",
            "Requirement already satisfied: MarkupSafe==2.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.1.3)\n",
            "Requirement already satisfied: matplotlib==3.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (3.8.0)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (1.3.0)\n",
            "Requirement already satisfied: networkx==3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (3.1)\n",
            "Requirement already satisfied: numpy==1.26.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (1.26.0)\n",
            "Requirement already satisfied: onnx==1.14.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (1.14.1)\n",
            "Requirement already satisfied: onnxruntime==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (1.16.0)\n",
            "Requirement already satisfied: opencv-python==4.8.0.76 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (4.8.0.76)\n",
            "Requirement already satisfied: packaging==23.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (23.1)\n",
            "Requirement already satisfied: pandas==2.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.1.1)\n",
            "Requirement already satisfied: Pillow>=10.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (10.4.0)\n",
            "Requirement already satisfied: protobuf==4.24.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (4.24.3)\n",
            "Requirement already satisfied: psutil==5.9.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo==9.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (9.0.0)\n",
            "Requirement already satisfied: pyparsing==3.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (2.8.2)\n",
            "Requirement already satisfied: pytz==2023.3.post1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (2023.3.post1)\n",
            "Requirement already satisfied: PyWavelets==1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (1.4.1)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (6.0.1)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (2.31.0)\n",
            "Requirement already satisfied: scikit-image==0.21.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (0.21.0)\n",
            "Requirement already satisfied: scipy==1.11.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (1.11.2)\n",
            "Requirement already satisfied: seaborn==0.12.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (0.12.2)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (1.16.0)\n",
            "Requirement already satisfied: sympy==1.12 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (1.12)\n",
            "Requirement already satisfied: tifffile==2023.9.18 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 43)) (2023.9.18)\n",
            "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 44)) (4.66.1)\n",
            "Requirement already satisfied: typing_extensions==4.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 45)) (4.8.0)\n",
            "Requirement already satisfied: tzdata==2023.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 46)) (2023.3)\n",
            "Requirement already satisfied: ultralytics==8.2.48 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 47)) (8.2.48)\n",
            "Requirement already satisfied: urllib3>=2.0.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 48)) (2.0.7)\n",
            "Requirement already satisfied: zipp==3.17.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 49)) (3.17.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.48->-r requirements.txt (line 47)) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.48->-r requirements.txt (line 47)) (0.19.0+cu121)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.2.48->-r requirements.txt (line 47)) (2.0.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.2.48->-r requirements.txt (line 47)) (2024.6.1)\n",
            "Obtaining file:///content/my_drive/MyDrive/easy_ViTPose\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: easy_ViTPose\n",
            "  Running setup.py develop for easy_ViTPose\n",
            "Successfully installed easy_ViTPose-1.1\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.8)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (71.0.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.2.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "%cd /content/my_drive/MyDrive/easy_ViTPose\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e .\n",
        "!pip install ipywidgets\n",
        "import sys\n",
        "sys.path.append('/content/my_drive/MyDrive/easy_ViTPose')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ZYotqeB3BH"
      },
      "source": [
        "Once complete, restart session when prompted. If the prompt does not apepar, restart it manually (Runtime -> Restart session) to make sure installed package versions are updated locally.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i55KxqOqBwKk"
      },
      "source": [
        "# Download the object detection and pose estimation models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p8K8pTOFYlA"
      },
      "source": [
        "Mount Google Drive to access the pre-trained model weights. [Note: provide link to public weights folder here]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_sHCjv3DBodU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af79059-8d8b-459d-8c50-465e7274d943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained pose model weights from: /content/my_drive/My Drive/tkd-ar/model_weights/ViTPose/pre-trained_weights/aic/vitpose-s-aic.pth\n",
            "Loading pre-trained detector model weights from: /content/my_drive/My Drive/tkd-ar/model_weights/YOLOv8/pre-trained_weights/yolov8n.pt\n"
          ]
        }
      ],
      "source": [
        "#@title Choose the specifications from the dropdown lists and run this cell\n",
        "\n",
        "MODEL_SIZE = 's'  #@param ['s', 'b', 'l', 'h']\n",
        "YOLO_SIZE = 'n'  #@param ['n', 's', 'm', 'l', 'x']\n",
        "DATASET = 'aic'  #@param ['coco_25', 'coco', 'wholebody', 'mpii', 'aic', 'ap10k', 'apt36k']\n",
        "ext = '.pth'\n",
        "ext_yolo = '.pt'\n",
        "\n",
        "root_path = '/content/my_drive/My Drive/tkd-ar/model_weights'\n",
        "pose_path = os.path.join(root_path, 'ViTPose/pre-trained_weights')\n",
        "pose_path = os.path.join(pose_path, f'{DATASET}/vitpose-' + MODEL_SIZE + f'-{DATASET}') + ext\n",
        "detector_path = os.path.join(root_path, 'YOLOv8/pre-trained_weights')\n",
        "detector_path = os.path.join(detector_path, 'yolov8' + YOLO_SIZE + ext_yolo)\n",
        "print(f'Loading pre-trained pose model weights from: {pose_path}')\n",
        "print(f'Loading pre-trained detector model weights from: {detector_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnHtFURjFx0V"
      },
      "source": [
        "Prepare the models for inference using the easy_ViTPose repository. Note, if an error occurrs at this step, restart the environment and rerun this cell to update the package versions.\n",
        "\n",
        "Note setting is_video=True will load the basic SORT tracker to label individuals' bounding boxes between frames.\n",
        "\n",
        "[Note provide options for better trackers later]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4R-E7zpphoch"
      },
      "outputs": [],
      "source": [
        "# # Check on still image\n",
        "# from easy_ViTPose import VitInference\n",
        "# model = VitInference(pose_path, detector_path, MODEL_SIZE,\n",
        "#                      dataset=DATASET, yolo_size=320, is_video=False)\n",
        "\n",
        "# # Run inference on example image\n",
        "# import numpy as np\n",
        "# from io import BytesIO\n",
        "# from PIL import Image\n",
        "# from urllib.request import urlopen\n",
        "\n",
        "# # Load image and run inference\n",
        "# url = 'https://i.ibb.co/gVQpNqF/imggolf.jpg'\n",
        "# img = np.array(Image.open(BytesIO(urlopen(url).read())), dtype=np.uint8)\n",
        "\n",
        "# frame_keypoints = model.inference(img)\n",
        "# img = model.draw(show_yolo=True)\n",
        "\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# cv2_imshow(img[..., ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hi9fpgCnFvYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36599d64-746b-4191-eb4a-5a14003b078d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py:527: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file, map_location='cpu'), file  # load\n",
            "/content/easy_ViTPose/easy_ViTPose/inference.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(model, map_location='cpu')\n"
          ]
        }
      ],
      "source": [
        "from easy_ViTPose import VitInference\n",
        "model = VitInference(pose_path, detector_path, MODEL_SIZE,\n",
        "                     dataset=DATASET, yolo_size=320, is_video=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UobB1B_mGGsQ"
      },
      "source": [
        "# Load the videos for inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNt5vgZtGkZy"
      },
      "source": [
        "Set paths for the unannotated video, the output video for the results of the inference, and the json file containing the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3JkpM9hGnhP"
      },
      "outputs": [],
      "source": [
        "# #@title Video paths\n",
        "\n",
        "# import ipywidgets as widgets\n",
        "# from IPython.display import display\n",
        "\n",
        "# # Define the input widgets\n",
        "# video_path_widget = widgets.Text(\n",
        "#     value='/content/drive/MyDrive/Taekwondo videos/clipped_videos/P01/2_1_base_P01_base.mp4',\n",
        "#     placeholder='Enter the path to the input video',\n",
        "#     description='Video Path:',\n",
        "#     disabled=False\n",
        "# )\n",
        "\n",
        "# output_video_path_widget = widgets.Text(\n",
        "#     value='/content/drive/MyDrive/Taekwondo videos/clipped_videos/P01/output_2_1_base_P01_base.mp4',\n",
        "#     placeholder='Enter the path to save the output video',\n",
        "#     description='Output Video Path:',\n",
        "#     disabled=False\n",
        "# )\n",
        "\n",
        "# output_json_path_widget = widgets.Text(\n",
        "#     value='/content/drive/MyDrive/Taekwondo videos/clipped_videos/P01/2_1_base_P01_base.json',\n",
        "#     placeholder='Enter the path to save the JSON output',\n",
        "#     description='Output JSON Path:',\n",
        "#     disabled=False\n",
        "# )\n",
        "\n",
        "# # Display the widgets\n",
        "# display(video_path_widget)\n",
        "# display(output_video_path_widget)\n",
        "# display(output_json_path_widget)\n",
        "\n",
        "# # Button to confirm the paths\n",
        "# button = widgets.Button(description=\"Confirm\")\n",
        "\n",
        "# # Dictionary to store the paths\n",
        "# paths = {}\n",
        "\n",
        "# def on_button_click(b):\n",
        "#     \"\"\"\n",
        "#     Captures the values entered by the user and stores them in the paths dictionary.\n",
        "#     \"\"\"\n",
        "#     paths['video_path'] = video_path_widget.value\n",
        "#     paths['output_video_path'] = output_video_path_widget.value\n",
        "#     paths['output_json_path'] = output_json_path_widget.value\n",
        "\n",
        "#     print(f\"Video Path: {paths['video_path']}\")\n",
        "#     print(f\"Output Video Path: {paths['output_video_path']}\")\n",
        "#     print(f\"Output JSON Path: {paths['output_json_path']}\")\n",
        "\n",
        "# button.on_click(on_button_click)\n",
        "# display(button)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0xGoXcv4SPE"
      },
      "source": [
        "Verify path selection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdBNW-bAl1hi"
      },
      "outputs": [],
      "source": [
        "# video_path = paths.get('video_path', '')\n",
        "# output_video_path = paths.get('output_video_path', '')\n",
        "# output_json_path = paths.get('output_json_path', '')\n",
        "\n",
        "# print(f\"Using Video Path: {video_path}\")\n",
        "# print(f\"Using Output Video Path: {output_video_path}\")\n",
        "# print(f\"Using Output JSON Path: {output_json_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s4r_nRnyJL2C"
      },
      "outputs": [],
      "source": [
        "#@title Choose the behaviour of the inference script\n",
        "\n",
        "ANNOTATE_VIDEO = 'True'  #@param ['True', 'False']\n",
        "SHOW_FRAMES = 'True'  #@param ['True', 'False']\n",
        "OUTPUT_JSON_LABELS = 'True'  #@param ['True', 'False']\n",
        "SHOW_BBOX = 'True'  #@param ['True', 'False']\n",
        "\n",
        "prepare_output_video = ANNOTATE_VIDEO == 'True'\n",
        "show_frames = SHOW_FRAMES == 'True'\n",
        "output_json_labels = OUTPUT_JSON_LABELS == 'True'\n",
        "show_bbox = SHOW_BBOX == 'True'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IakQltPLAEy"
      },
      "source": [
        "ANNOTATE_VIDEO=True will ensure that a copy of the input video with the bounding boxes and pose annotations  overlayed will be saved to the output_video_path.\n",
        "\n",
        "SHOW_FRAMES=True displays the first frame of the video with the annotations overlayed to verify whether the model is working as expected.\n",
        "\n",
        "OUTPUT_JSON_LABELS=True means that the frame-by-frame annotations will be written to the output_json_labels format in the structure laid out below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6483dUkK3nm"
      },
      "source": [
        "Define the structure of the output JSON file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4QkcQ23yK2_O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def create_json_output_format(\n",
        "    keypoints_data, skeleton, width, height, fps, yolo_full_name, vitpose_full_name, dataset, interval_length=3.1\n",
        "):\n",
        "    \"\"\"\n",
        "    Create a JSON formatted dictionary with keypoints data and video properties, grouped into intervals.\n",
        "\n",
        "    Args:\n",
        "        keypoints_data (list): List of dictionaries containing keypoints for each frame.\n",
        "        skeleton (list): List of skeleton keypoints.\n",
        "        width (int): Width of the video frame.\n",
        "        height (int): Height of the video frame.\n",
        "        fps (float): Frames per second of the video.\n",
        "        yolo_full_name (str): Full name of the YOLO model used.\n",
        "        vitpose_full_name (str): Full name of the ViTPose model used.\n",
        "        dataset (str): Dataset used for pose estimation.\n",
        "        interval_length (float): Length of each interval in seconds (default is 3.1 seconds).\n",
        "\n",
        "    Returns:\n",
        "        dict: JSON formatted dictionary.\n",
        "    \"\"\"\n",
        "    aspect_ratio = width / height  # Calculate aspect ratio\n",
        "\n",
        "    # Calculate the exact number of frames per interval\n",
        "    frames_per_interval_exact = fps * interval_length\n",
        "    frames_per_interval_floor = int(np.floor(frames_per_interval_exact))\n",
        "    remainder = frames_per_interval_exact - frames_per_interval_floor\n",
        "    remainder_accumulated = 0\n",
        "\n",
        "    # Skip the first two frames as warm-up\n",
        "    keypoints_data = keypoints_data[2:]\n",
        "\n",
        "    # Group frames into intervals\n",
        "    techniques = {}\n",
        "    technique_idx = 0\n",
        "\n",
        "    start_idx = 0\n",
        "    while start_idx < len(keypoints_data):\n",
        "        # Determine the number of frames for the current interval\n",
        "        interval_frames_count = frames_per_interval_floor\n",
        "        remainder_accumulated += remainder\n",
        "        if remainder_accumulated >= 1:\n",
        "            interval_frames_count += 1\n",
        "            remainder_accumulated -= 1\n",
        "\n",
        "        # Extract frames for the current interval\n",
        "        end_idx = min(start_idx + interval_frames_count, len(keypoints_data))\n",
        "        interval_frames = keypoints_data[start_idx:end_idx]\n",
        "\n",
        "        # Group frames under the current technique\n",
        "        techniques[technique_idx] = {\n",
        "            'frames': []\n",
        "        }\n",
        "\n",
        "        for frame_data in interval_frames:\n",
        "            persons = []\n",
        "\n",
        "            for person_id, keypoints_info in frame_data['keypoints'].items():\n",
        "                keypoints_array = np.array(keypoints_info)\n",
        "                num_keypoints = len(skeleton)  # Assume skeleton provides the number of keypoints\n",
        "\n",
        "                # Check if the keypoints are already in the correct shape\n",
        "                if keypoints_array.size != num_keypoints * 3:\n",
        "                    print(f\"Warning: Unexpected keypoints size for person {person_id} in frame {frame_data['frame']}\")\n",
        "                    continue\n",
        "\n",
        "                # Use already-reshaped keypoints if possible\n",
        "                keypoints_array = keypoints_array.reshape(num_keypoints, 3)\n",
        "                keypoints_list = keypoints_array.tolist()\n",
        "\n",
        "                persons.append({\n",
        "                    'person_id': person_id,\n",
        "                    'keypoints': keypoints_list\n",
        "                })\n",
        "\n",
        "            techniques[technique_idx]['frames'].append({\n",
        "                'frame_number': frame_data['frame'],\n",
        "                'persons': persons\n",
        "            })\n",
        "\n",
        "        # Check if the last technique needs padding\n",
        "        if len(interval_frames) < interval_frames_count:\n",
        "            last_frame = techniques[technique_idx]['frames'][-1]\n",
        "            for _ in range(interval_frames_count - len(interval_frames)):\n",
        "                techniques[technique_idx]['frames'].append(last_frame)\n",
        "\n",
        "        # Increment technique index and update start index for the next interval\n",
        "        technique_idx += 1\n",
        "        start_idx = end_idx\n",
        "\n",
        "    # Construct the final JSON structure\n",
        "    return {\n",
        "        'techniques': techniques,\n",
        "        'detection_model': yolo_full_name,\n",
        "        'pose_model': vitpose_full_name,\n",
        "        'pose_format': dataset,\n",
        "        'skeleton': skeleton,\n",
        "        'camera_properties': {\n",
        "            'width': width,\n",
        "            'height': height,\n",
        "            'aspect_ratio': aspect_ratio,\n",
        "            'fps': fps\n",
        "        },\n",
        "        'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I24iNHa3KMls"
      },
      "source": [
        "Run inference on the chosen video. Note, the model must be reset each time to avoid confusion with the tracker module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gx2sgTG03fcy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import tqdm\n",
        "import time\n",
        "from datetime import datetime\n",
        "from google.colab.patches import cv2_imshow\n",
        "from easy_ViTPose.vit_utils.inference import NumpyEncoder, VideoReader\n",
        "from easy_ViTPose.inference import VitInference\n",
        "from easy_ViTPose.vit_utils.visualization import joints_dict\n",
        "\n",
        "def setup_video_reader(video_path):\n",
        "    \"\"\"\n",
        "    Initialize the video reader and capture video properties.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "\n",
        "    Returns:\n",
        "        VideoReader, int, int, int, float: Video reader object, width, height, total_frames, fps.\n",
        "    \"\"\"\n",
        "    reader = VideoReader(video_path)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    cap.release()\n",
        "\n",
        "    return reader, width, height, total_frames, fps\n",
        "\n",
        "def initialize_video_writer(output_video_path, width, height, fps):\n",
        "    \"\"\"\n",
        "    Initialize the video writer for saving the output video.\n",
        "\n",
        "    Args:\n",
        "        output_video_path (str): Path to save the output video.\n",
        "        width (int): Width of the video frames.\n",
        "        height (int): Height of the video frames.\n",
        "        fps (float): Frames per second of the video.\n",
        "\n",
        "    Returns:\n",
        "        cv2.VideoWriter: Video writer object.\n",
        "    \"\"\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "    return out\n",
        "\n",
        "def process_frames(reader, total_frames, model, num_keypoints):\n",
        "    \"\"\"\n",
        "    Process each frame in the video, extract keypoints, and handle missing data.\n",
        "\n",
        "    Args:\n",
        "        reader (VideoReader): Video reader object.\n",
        "        total_frames (int): Total number of frames in the video.\n",
        "        model (VitInference): Pose estimation model.\n",
        "        num_keypoints (int): Number of keypoints expected for each person.\n",
        "\n",
        "    Returns:\n",
        "        list: Processed keypoints data for all frames.\n",
        "    \"\"\"\n",
        "    keypoints_data = []\n",
        "\n",
        "    for ith, img in tqdm.tqdm(enumerate(reader), total=total_frames):\n",
        "        t0 = time.time()\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"Frame {ith} is None, skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Perform inference to get keypoints\n",
        "        frame_keypoints = model.inference(img)\n",
        "\n",
        "        if not frame_keypoints:\n",
        "            # Handle missing keypoints by labeling them as empty\n",
        "            detected_keypoints = {\n",
        "                # No person detected, use NaN for the person_id to preserve frame count\n",
        "                \"NaN\": np.full((num_keypoints, 3), np.nan).flatten()\n",
        "            }\n",
        "        else:\n",
        "            detected_keypoints = {}\n",
        "            for person_id, keypoints in frame_keypoints.items():\n",
        "                keypoints_array = np.array(keypoints).reshape(-1, 3)\n",
        "\n",
        "                # Directly use detected keypoints, label missing keypoints as NaN\n",
        "                detected_keypoints[person_id] = np.nan_to_num(keypoints_array.flatten(), nan=np.nan)\n",
        "\n",
        "        keypoints_data.append({\n",
        "            'frame': ith,\n",
        "            'keypoints': detected_keypoints,\n",
        "            'processing_time': time.time() - t0\n",
        "        })\n",
        "\n",
        "    return keypoints_data\n",
        "\n",
        "def process_video_showing_output(reader, total_frames, model, num_keypoints, output_video_path, fps=30, frame_size=(640, 480)):\n",
        "    \"\"\"\n",
        "    Process each frame in the video, extract keypoints, handle missing data, and optionally save output to a video file.\n",
        "\n",
        "    Args:\n",
        "        reader (VideoReader): Video reader object.\n",
        "        total_frames (int): Total number of frames in the video.\n",
        "        model (VitInference): Pose estimation model.\n",
        "        num_keypoints (int): Number of keypoints expected for each person.\n",
        "        output_video_path (str): Path to save the output video.\n",
        "        save_video (bool): Flag to determine if the video should be saved.\n",
        "        fps (int): Frames per second for the output video.\n",
        "        frame_size (tuple): Dimensions of the video frame.\n",
        "\n",
        "    Returns:\n",
        "        list: Processed keypoints data for all frames.\n",
        "    \"\"\"\n",
        "    keypoints_data = []\n",
        "\n",
        "    out = initialize_video_writer(output_video_path, frame_size[0], frame_size[1], fps)\n",
        "\n",
        "    for ith, img in tqdm.tqdm(enumerate(reader), total=total_frames):\n",
        "        t0 = time.time()\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"Frame {ith} is None, skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Perform inference to get keypoints\n",
        "        frame_keypoints = model.inference(img)\n",
        "\n",
        "        img_with_keypoints = model.draw(show_yolo=True)[..., ::-1]  # Convert to BGR for OpenCV\n",
        "        out.write(img_with_keypoints)\n",
        "\n",
        "        if not frame_keypoints:\n",
        "            # Handle missing keypoints by labeling them as empty\n",
        "            detected_keypoints = {\n",
        "                # No person detected, use NaN for the person_id\n",
        "                \"NaN\": np.full((num_keypoints, 3), np.nan).flatten()\n",
        "            }\n",
        "        else:\n",
        "            detected_keypoints = {}\n",
        "            for person_id, keypoints in frame_keypoints.items():\n",
        "                keypoints_array = np.array(keypoints).reshape(-1, 3)\n",
        "\n",
        "                # Directly use detected keypoints, label missing keypoints as NaN\n",
        "                detected_keypoints[person_id] = np.nan_to_num(keypoints_array.flatten(), nan=np.nan)\n",
        "\n",
        "        keypoints_data.append({\n",
        "            'frame': ith,\n",
        "            'keypoints': detected_keypoints,\n",
        "            'processing_time': time.time() - t0\n",
        "        })\n",
        "\n",
        "    out.release()\n",
        "    return keypoints_data\n",
        "\n",
        "def save_json_output(output_json_path, keypoints_data, model, width, height, fps, yolo_size, model_size, dataset):\n",
        "    \"\"\"\n",
        "    Save the keypoints data to a JSON file.\n",
        "\n",
        "    Args:\n",
        "        output_json_path (str): Path to save the output JSON file.\n",
        "        keypoints_data (list): Processed keypoints data.\n",
        "        model (VitInference): Pose estimation model.\n",
        "        width (int): Width of the video frames.\n",
        "        height (int): Height of the video frames.\n",
        "        fps (float): Frames per second of the video.\n",
        "        yolo_size (str): YOLO model size.\n",
        "        model_size (str): Pose model size.\n",
        "        dataset (str): Dataset used for pose estimation.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    skeleton = joints_dict()[model.dataset]['keypoints']\n",
        "    yolo_size_mapping = {\n",
        "        's': 'yolov8s',\n",
        "        'n': 'yolov8n',\n",
        "        'm': 'yolov8m',\n",
        "        'l': 'yolov8l',\n",
        "        'x': 'yolov8x'\n",
        "    }\n",
        "    vitpose_size_mapping = {\n",
        "        's': 'vitpose-s',\n",
        "        'b': 'vitpose-b',\n",
        "        'l': 'vitpose-l',\n",
        "        'h': 'vitpose-h'\n",
        "    }\n",
        "    yolo_full_name = yolo_size_mapping.get(yolo_size, 'unknown_yolo_size')\n",
        "    vitpose_full_name = f\"{vitpose_size_mapping.get(model_size, 'unknown_vitpose_size')}-{dataset}\"\n",
        "\n",
        "    output_data = create_json_output_format(keypoints_data, skeleton, width, height, fps, yolo_full_name, vitpose_full_name, dataset)\n",
        "\n",
        "    with open(output_json_path, 'w') as f:\n",
        "        json.dump(output_data, f, cls=NumpyEncoder)\n",
        "\n",
        "def display_first_frame(output_video_path):\n",
        "    \"\"\"\n",
        "    Display the first frame of the processed video for demonstration.\n",
        "\n",
        "    Args:\n",
        "        output_video_path (str): Path to the output video file.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(output_video_path)\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        cv2_imshow(frame)\n",
        "    cap.release()\n",
        "\n",
        "def output_statistics(keypoints_data, fps_list, tot_time):\n",
        "    \"\"\"\n",
        "    Output performance statistics of the video processing.\n",
        "\n",
        "    Args:\n",
        "        keypoints_data (list): Processed keypoints data.\n",
        "        fps_list (list): List of frame processing times.\n",
        "        tot_time (float): Total processing time.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    tot_poses = sum(len(k['keypoints']) for k in keypoints_data)\n",
        "    print(f'Mean inference FPS: {1 / np.mean(fps_list):.2f}')\n",
        "    print(f'Total poses predicted: {tot_poses}, mean per frame: {(tot_poses / len(keypoints_data)):.2f}')\n",
        "    print(f'Mean FPS per pose: {(tot_poses / tot_time):.2f}')\n",
        "\n",
        "def process_video(model, keypoints, video_path, output_json_path, output_video_path='output_video.mp4', prepare_output_video=False, show_frames=False, yolo_size='s', model_size='b', dataset='coco', interpolate_threshold=3):\n",
        "    \"\"\"\n",
        "    Main function to process a video file, extract and smooth pose keypoints, and save results.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the input video file.\n",
        "        output_json_path (str): Path to save the output JSON file.\n",
        "        output_video_path (str): Path to save the output video with keypoints overlay.\n",
        "        prepare_output_video (bool): Whether to prepare an output video with keypoints overlay.\n",
        "        show_frames (bool): Whether to display the first frame of the processed video.\n",
        "        yolo_size (str): Size of the YOLO model.\n",
        "        model_size (str): Size of the pose estimation model.\n",
        "        dataset (str): Dataset format for pose estimation.\n",
        "        interpolate_threshold (int): Maximum number of consecutive missing frames to interpolate.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    reader, width, height, total_frames, fps = setup_video_reader(video_path)\n",
        "\n",
        "    if prepare_output_video:\n",
        "        print(\"Preparing output video...\")\n",
        "        keypoints_data = process_video_showing_output(reader, total_frames, model, keypoints, output_video_path, fps=fps, frame_size=(width, height))\n",
        "    else:\n",
        "        print(\"Processing frames without output video...\")\n",
        "        keypoints_data = process_frames(reader, total_frames, model, keypoints)\n",
        "\n",
        "    save_json_output(output_json_path, keypoints_data, model, width, height, fps, yolo_size, model_size, dataset)\n",
        "\n",
        "    if show_frames:\n",
        "        display_first_frame(output_video_path)\n",
        "\n",
        "    fps_list = [frame['processing_time'] for frame in keypoints_data]\n",
        "    tot_time = sum(fps_list)\n",
        "    output_statistics(keypoints_data, fps_list, tot_time)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LTOAe0sIMs7_"
      },
      "outputs": [],
      "source": [
        "def get_keypoint_no(skel_format):\n",
        "  if skel_format == 'coco':\n",
        "    return 17\n",
        "  elif skel_format == 'coco_25':\n",
        "    return 25\n",
        "  elif skel_format == 'mpii':\n",
        "    return 16\n",
        "  elif skel_format == 'aic':\n",
        "    return 14\n",
        "  elif skel_format == 'apt36k':\n",
        "    print(\"Warning: This pose format is for labelling animals.\")\n",
        "    return 36\n",
        "  elif skel_format == 'ap10k':\n",
        "    print(\"Warning: This pose format is for labelling animals.\")\n",
        "    return 10 # Animal pose estimation\n",
        "  elif skel_format == 'wholebody':\n",
        "    print(\"Warning: Labels 132 keypoints, most of which are in the face and hands.\")\n",
        "    return 132 # Whole body COCO pose estimation, with many face and hand keyoints\n",
        "  else:\n",
        "    raise ValueError(f\"Unsupported skeleton format: {skel_format}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test annotations"
      ],
      "metadata": {
        "id": "FC22meio7dTG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ilOrMK1dUYTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4f61ee-1b7b-47d2-d767-7ff09b8f2a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing output video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/8479 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 0.550s exceeded\n",
            "  5%|▌         | 437/8479 [00:31<08:31, 15.72it/s]"
          ]
        }
      ],
      "source": [
        "# Test annotations\n",
        "keypoints = get_keypoint_no(DATASET)\n",
        "participant = 'P02'\n",
        "camera = 'c2'\n",
        "input_path = f'/content/my_drive/MyDrive/tkd-ar/video_data/clipped_videos/{participant}/{participant}_{camera}.mp4'\n",
        "output_path = f'/content/my_drive/MyDrive/test_length_{participant}_{camera}.mp4'\n",
        "json_path = f'/content/my_drive/MyDrive/test_length_{participant}_{camera}.json'\n",
        "# input_path = '/content/my_drive/MyDrive/Taekwondo videos/source_files/P08_c1_clipped.mp4'\n",
        "# json_path = '/content/my_drive/MyDrive/Taekwondo videos/source_files/P08_c1_clipped_output.json'\n",
        "# output_path = '/content/my_drive/MyDrive/Taekwondo videos/source_files/P08_c1_clipped_output.mp4'\n",
        "process_video(model, keypoints, input_path, json_path, output_path, prepare_output_video=prepare_output_video, show_frames=show_frames, yolo_size=YOLO_SIZE, model_size=MODEL_SIZE, dataset=DATASET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eusKC8Og4mht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e96ab0-6dd8-41c2-b21d-886db7e44d40"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pre-trained pose model weights from: /content/my_drive/My Drive/pose_models/ViTPose/pre-trained_weights/coco_25/vitpose-h-coco_25.pth\n",
            "Loading pre-trained detector model weights from: /content/my_drive/My Drive/pose_models/YOLOv8/pre-trained_weights/yolov8m.pt\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P01\n",
            "Processing participant folder: P01\n",
            "Found file: P01_c1.mp4\n",
            "Processing video file: P01_c1.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P01/P01_c1.mp4 because JSON output already exists as P01_c1_vitpose_h_yolo_m.json\n",
            "Found file: P01_c2.mp4\n",
            "Processing video file: P01_c2.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P01/P01_c2.mp4 because JSON output already exists as P01_c2_vitpose_h_yolo_m.json\n",
            "Found file: P01_c3.mp4\n",
            "Processing video file: P01_c3.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P01/P01_c3.mp4 because JSON output already exists as P01_c3_vitpose_h_yolo_m.json\n",
            "Found file: P01_c4.mp4\n",
            "Processing video file: P01_c4.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P01/P01_c4.mp4 because JSON output already exists as P01_c4_vitpose_h_yolo_m.json\n",
            "Found file: P01_c5.mp4\n",
            "Processing video file: P01_c5.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P01/P01_c5.mp4 because JSON output already exists as P01_c5_vitpose_h_yolo_m.json\n",
            "Found file: P01_c6.mp4\n",
            "Processing video file: P01_c6.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P01/P01_c6.mp4 because JSON output already exists as P01_c6_vitpose_h_yolo_m.json\n",
            "Found file: P01_c7.mp4\n",
            "Processing video file: P01_c7.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P01/P01_c7.mp4 because JSON output already exists as P01_c7_vitpose_h_yolo_m.json\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P04\n",
            "Processing participant folder: P04\n",
            "Found file: P04_c2.mp4\n",
            "Processing video file: P04_c2.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P04/P04_c2.mp4 because JSON output already exists as P04_c2_vitpose_h_yolo_m.json\n",
            "Found file: P04_c3.mp4\n",
            "Processing video file: P04_c3.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P04/P04_c3.mp4 because JSON output already exists as P04_c3_vitpose_h_yolo_m.json\n",
            "Found file: P04_c4.mp4\n",
            "Processing video file: P04_c4.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P04/P04_c4.mp4 because JSON output already exists as P04_c4_vitpose_h_yolo_m.json\n",
            "Found file: P04_c5.mp4\n",
            "Processing video file: P04_c5.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P04/P04_c5.mp4 because JSON output already exists as P04_c5_vitpose_h_yolo_m.json\n",
            "Found file: P04_c6.mp4\n",
            "Processing video file: P04_c6.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P04/P04_c6.mp4 because JSON output already exists as P04_c6_vitpose_h_yolo_m.json\n",
            "Found file: P04_c7.mp4\n",
            "Processing video file: P04_c7.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P04/P04_c7.mp4 because JSON output already exists as P04_c7_vitpose_h_yolo_m.json\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P05\n",
            "Processing participant folder: P05\n",
            "Found file: P05_c2.mp4\n",
            "Processing video file: P05_c2.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P05/P05_c2.mp4 because JSON output already exists as P05_c2_vitpose_h_yolo_m.json\n",
            "Found file: P05_c3.mp4\n",
            "Processing video file: P05_c3.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P05/P05_c3.mp4 because JSON output already exists as P05_c3_vitpose_h_yolo_m.json\n",
            "Found file: P05_c4.mp4\n",
            "Processing video file: P05_c4.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P05/P05_c4.mp4 because JSON output already exists as P05_c4_vitpose_h_yolo_m.json\n",
            "Found file: P05_c5.mp4\n",
            "Processing video file: P05_c5.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P05/P05_c5.mp4 because JSON output already exists as P05_c5_vitpose_h_yolo_m.json\n",
            "Found file: P05_c6.mp4\n",
            "Processing video file: P05_c6.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P05/P05_c6.mp4 because JSON output already exists as P05_c6_vitpose_h_yolo_m.json\n",
            "Found file: P05_c7.mp4\n",
            "Processing video file: P05_c7.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P05/P05_c7.mp4 because JSON output already exists as P05_c7_vitpose_h_yolo_m.json\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P06\n",
            "Processing participant folder: P06\n",
            "Found file: P06_c2.mp4\n",
            "Processing video file: P06_c2.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P06/P06_c2.mp4 because JSON output already exists as P06_c2_vitpose_h_yolo_m.json\n",
            "Found file: P06_c3.mp4\n",
            "Processing video file: P06_c3.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P06/P06_c3.mp4 because JSON output already exists as P06_c3_vitpose_h_yolo_m.json\n",
            "Found file: P06_c5.mp4\n",
            "Processing video file: P06_c5.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P06/P06_c5.mp4 because JSON output already exists as P06_c5_vitpose_h_yolo_m.json\n",
            "Found file: P06_c6.mp4\n",
            "Processing video file: P06_c6.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P06/P06_c6.mp4 because JSON output already exists as P06_c6_vitpose_h_yolo_m.json\n",
            "Found file: P06_c7.mp4\n",
            "Processing video file: P06_c7.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P06/P06_c7.mp4 because JSON output already exists as P06_c7_vitpose_h_yolo_m.json\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P07\n",
            "Processing participant folder: P07\n",
            "Found file: P07_c1.mp4\n",
            "Processing video file: P07_c1.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P07/P07_c1.mp4 because JSON output already exists as P07_c1_vitpose_h_yolo_m.json\n",
            "Found file: P07_c2.mp4\n",
            "Processing video file: P07_c2.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P07/P07_c2.mp4 because JSON output already exists as P07_c2_vitpose_h_yolo_m.json\n",
            "Found file: P07_c3.mp4\n",
            "Processing video file: P07_c3.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P07/P07_c3.mp4 because JSON output already exists as P07_c3_vitpose_h_yolo_m.json\n",
            "Found file: P07_c4.mp4\n",
            "Processing video file: P07_c4.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P07/P07_c4.mp4 because JSON output already exists as P07_c4_vitpose_h_yolo_m.json\n",
            "Found file: P07_c5.mp4\n",
            "Processing video file: P07_c5.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P07/P07_c5.mp4 because JSON output already exists as P07_c5_vitpose_h_yolo_m.json\n",
            "Found file: P07_c6.mp4\n",
            "Processing video file: P07_c6.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P07/P07_c6.mp4 because JSON output already exists as P07_c6_vitpose_h_yolo_m.json\n",
            "Found file: P07_c7.mp4\n",
            "Processing video file: P07_c7.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P07/P07_c7.mp4 because JSON output already exists as P07_c7_vitpose_h_yolo_m.json\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P02\n",
            "Processing participant folder: P02\n",
            "Found file: P02_c1.mp4\n",
            "Processing video file: P02_c1.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P02/P02_c1.mp4 because JSON output already exists as P02_c1_vitpose_h_yolo_m.json\n",
            "Found file: P02_c2.mp4\n",
            "Processing video file: P02_c2.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P02/P02_c2.mp4 because JSON output already exists as P02_c2_vitpose_h_yolo_m.json\n",
            "Found file: P02_c3.mp4\n",
            "Processing video file: P02_c3.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P02/P02_c3.mp4 because JSON output already exists as P02_c3_vitpose_h_yolo_m.json\n",
            "Found file: P02_c4.mp4\n",
            "Processing video file: P02_c4.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P02/P02_c4.mp4 because JSON output already exists as P02_c4_vitpose_h_yolo_m.json\n",
            "Found file: P02_c6.mp4\n",
            "Processing video file: P02_c6.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P02/P02_c6.mp4 because JSON output already exists as P02_c6_vitpose_h_yolo_m.json\n",
            "Found file: P02_c7.mp4\n",
            "Processing video file: P02_c7.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P02/P02_c7.mp4 because JSON output already exists as P02_c7_vitpose_h_yolo_m.json\n",
            "Found file: P02_c5.mp4\n",
            "Processing video file: P02_c5.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P02/P02_c5.mp4 because JSON output already exists as P02_c5_vitpose_h_yolo_m.json\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P03\n",
            "Processing participant folder: P03\n",
            "Found file: P03_c1.mp4\n",
            "Processing video file: P03_c1.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P03/P03_c1.mp4 because JSON output already exists as P03_c1_vitpose_h_yolo_m.json\n",
            "Found file: P03_c2.mp4\n",
            "Processing video file: P03_c2.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P03/P03_c2.mp4 because JSON output already exists as P03_c2_vitpose_h_yolo_m.json\n",
            "Found file: P03_c3.mp4\n",
            "Processing video file: P03_c3.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P03/P03_c3.mp4 because JSON output already exists as P03_c3_vitpose_h_yolo_m.json\n",
            "Found file: P03_c4.mp4\n",
            "Processing video file: P03_c4.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P03/P03_c4.mp4 because JSON output already exists as P03_c4_vitpose_h_yolo_m.json\n",
            "Found file: P03_c5.mp4\n",
            "Processing video file: P03_c5.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P03/P03_c5.mp4 because JSON output already exists as P03_c5_vitpose_h_yolo_m.json\n",
            "Found file: P03_c6.mp4\n",
            "Processing video file: P03_c6.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P03/P03_c6.mp4 because JSON output already exists as P03_c6_vitpose_h_yolo_m.json\n",
            "Found file: P03_c7.mp4\n",
            "Processing video file: P03_c7.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P03/P03_c7.mp4 because JSON output already exists as P03_c7_vitpose_h_yolo_m.json\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P08\n",
            "Processing participant folder: P08\n",
            "Found file: P08_c1.mp4\n",
            "Processing video file: P08_c1.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P08/P08_c1.mp4 because JSON output already exists as P08_c1_vitpose_h_yolo_m.json\n",
            "Found file: P08_c2.mp4\n",
            "Processing video file: P08_c2.mp4\n",
            "Skipping /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P08/P08_c2.mp4 because JSON output already exists as P08_c2_vitpose_h_yolo_m.json\n",
            "Found file: P08_c3.mp4\n",
            "Processing video file: P08_c3.mp4\n",
            "Found file: P08_c4.mp4\n",
            "Processing video file: P08_c4.mp4\n",
            "Found file: P08_c5b.mp4\n",
            "Processing video file: P08_c5b.mp4\n",
            "Found file: P08_c6.mp4\n",
            "Processing video file: P08_c6.mp4\n",
            "Found file: P08_c5a.mp4\n",
            "Processing video file: P08_c5a.mp4\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/zOld\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/coco_25_vitpose_s_yolo_s\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/coco_25_vitpose_s_yolo_m\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/coco_25_vitpose_l_yolo_m\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/mpii_vitpose_l_yolo_m\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/coco_vitpose_l_yolo_m\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/aic_vitpose_l_yolo_m\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/technique_timestamps\n",
            "Checking folder: /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/coco_25_vitpose_h_yolo_m\n",
            "Processing /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P08/P08_c3.mp4:\n",
            "Processing frames without output video...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 39061/39111 [2:44:16<00:12,  3.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean inference FPS: 4.15\n",
            "Total poses predicted: 88792, mean per frame: 2.27\n",
            "Mean FPS per pose: 9.43\n",
            "Processing /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P08/P08_c4.mp4:\n",
            "Processing frames without output video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 39102/39249 [3:07:00<00:42,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean inference FPS: 3.52\n",
            "Total poses predicted: 105330, mean per frame: 2.69\n",
            "Mean FPS per pose: 9.49\n",
            "Processing /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P08/P08_c5b.mp4:\n",
            "Processing frames without output video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2159/2159 [09:13<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean inference FPS: 3.99\n",
            "Total poses predicted: 5060, mean per frame: 2.34\n",
            "Mean FPS per pose: 9.34\n",
            "Processing /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P08/P08_c6.mp4:\n",
            "Processing frames without output video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 38844/38845 [3:21:17<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean inference FPS: 3.34\n",
            "Total poses predicted: 109863, mean per frame: 2.83\n",
            "Mean FPS per pose: 9.44\n",
            "Processing /content/my_drive/MyDrive/Taekwondo videos/clipped_videos/P08/P08_c5a.mp4:\n",
            "Processing frames without output video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 32292/32305 [1:32:02<00:02,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean inference FPS: 6.03\n",
            "Total poses predicted: 49389, mean per frame: 1.53\n",
            "Mean FPS per pose: 9.23\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def generate_video_paths(root, vitpose_version, yolo_version, dataset):\n",
        "    \"\"\"\n",
        "    Generate file paths for video processing for all participants and sessions.\n",
        "\n",
        "    Args:\n",
        "        root (str): Root directory where participant folders are located.\n",
        "        vitpose_version (str): Version of the ViTPose model used for naming outputs.\n",
        "        yolo_version (str): Version of the YOLO model used for naming outputs.\n",
        "        dataset (str): Dataset name used for naming the subfolder.\n",
        "\n",
        "    Returns:\n",
        "        list: List of lists containing paths [input_video, output_video, output_json].\n",
        "    \"\"\"\n",
        "    video_paths = []\n",
        "\n",
        "    # Define the base output directory structure\n",
        "    base_output_dir = os.path.join(root, f'{dataset}_vitpose_{vitpose_version}_yolo_{yolo_version}')\n",
        "\n",
        "    # Create base output directory if it does not exist\n",
        "    if not os.path.exists(base_output_dir):\n",
        "        os.makedirs(base_output_dir)\n",
        "        print(f\"Created directory: {base_output_dir}\")\n",
        "\n",
        "    # Traverse the root directory to find participant folders\n",
        "    for participant_folder in os.listdir(root):\n",
        "        participant_path = os.path.join(root, participant_folder)\n",
        "        print(f\"Checking folder: {participant_path}\")\n",
        "\n",
        "        # Ensure it's a directory and matches the \"PXX\" format\n",
        "        if os.path.isdir(participant_path) and participant_folder.startswith('P'):\n",
        "            print(f\"Processing participant folder: {participant_folder}\")\n",
        "            # Traverse each file in the participant folder\n",
        "            for file in os.listdir(participant_path):\n",
        "                print(f\"Found file: {file}\")\n",
        "                if file.endswith('.mp4'):  # Look for MP4 video files\n",
        "                    print(f\"Processing video file: {file}\")\n",
        "                    # Construct input and output paths\n",
        "                    input_video = os.path.join(participant_path, file)\n",
        "                    session_name = os.path.splitext(file)[0]  # Remove the file extension for naming\n",
        "\n",
        "                    output_video = f'output_{session_name}_vitpose_{vitpose_version}_yolo_{yolo_version}.mp4'\n",
        "                    output_json = f'{session_name}_vitpose_{vitpose_version}_yolo_{yolo_version}.json'\n",
        "\n",
        "                    # Define the full path for JSON output\n",
        "                    output_video_path = os.path.join(base_output_dir, participant_folder, output_video)\n",
        "                    output_json_path = os.path.join(base_output_dir, participant_folder, output_json)\n",
        "\n",
        "                    # Create participant subdirectory if it does not exist\n",
        "                    participant_output_dir = os.path.join(base_output_dir, participant_folder)\n",
        "                    if not os.path.exists(participant_output_dir):\n",
        "                        os.makedirs(participant_output_dir)\n",
        "                        print(f\"Created directory: {participant_output_dir}\")\n",
        "\n",
        "                    # Check if output JSON already exists in the JSON directory\n",
        "                    if os.path.exists(output_json_path):\n",
        "                        print(f\"Skipping {input_video} because JSON output already exists as {output_json}\")\n",
        "                        continue\n",
        "\n",
        "                    # Append paths to video_paths list\n",
        "                    video_paths.append([\n",
        "                        input_video,\n",
        "                        output_video_path,\n",
        "                        output_json_path\n",
        "                    ])\n",
        "\n",
        "    return video_paths\n",
        "\n",
        "MODEL_SIZE = 's'  #@param ['s', 'b', 'l', 'h']\n",
        "YOLO_SIZE = 'n'  #@param ['n', 's', 'm', 'l', 'x']\n",
        "DATASET = 'aic'  #@param ['coco_25', 'coco', 'wholebody', 'mpii', 'aic', 'ap10k', 'apt36k']\n",
        "ext = '.pth'\n",
        "ext_yolo = '.pt'\n",
        "\n",
        "root_path = '/content/my_drive/My Drive/pose_models'\n",
        "pose_path = os.path.join(root_path, 'ViTPose/pre-trained_weights')\n",
        "pose_path = os.path.join(pose_path, f'{DATASET}/vitpose-' + MODEL_SIZE + f'-{DATASET}') + ext\n",
        "detector_path = os.path.join(root_path, 'YOLOv8/pre-trained_weights')\n",
        "detector_path = os.path.join(detector_path, 'yolov8' + YOLO_SIZE + ext_yolo)\n",
        "print(f'Loading pre-trained pose model weights from: {pose_path}')\n",
        "print(f'Loading pre-trained detector model weights from: {detector_path}')\n",
        "ANNOTATE_VIDEO = 'False'  #@param ['True', 'False']\n",
        "SHOW_FRAMES = 'False'  #@param ['True', 'False']\n",
        "OUTPUT_JSON_LABELS = 'True'  #@param ['True', 'False']\n",
        "SHOW_BBOX = 'False'  #@param ['True', 'False']\n",
        "\n",
        "prepare_output_video = ANNOTATE_VIDEO == 'True'\n",
        "show_frames = SHOW_FRAMES == 'True'\n",
        "output_json_labels = OUTPUT_JSON_LABELS == 'True'\n",
        "show_bbox = SHOW_BBOX == 'True'\n",
        "\n",
        "from easy_ViTPose import VitInference\n",
        "model = VitInference(pose_path, detector_path, MODEL_SIZE,\n",
        "                     dataset=DATASET, yolo_size=320, is_video=True)\n",
        "\n",
        "# Generate video paths for all videos in the directory\n",
        "video_paths = generate_video_paths('/content/my_drive/MyDrive/Taekwondo videos/clipped_videos', MODEL_SIZE, YOLO_SIZE, DATASET)\n",
        "\n",
        "keypoints = get_keypoint_no(DATASET)\n",
        "\n",
        "# Process each video using the generated paths\n",
        "for video in video_paths:\n",
        "    input_video, output_video, output_json = video\n",
        "\n",
        "    print(f\"Processing {input_video}:\")\n",
        "    process_video(model, keypoints, input_video, output_json, output_video, yolo_size=YOLO_SIZE, model_size=MODEL_SIZE, dataset=DATASET)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SejYlJVL1zNg"
      },
      "source": [
        "Single file run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JUA16O5TJIA"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# import json\n",
        "# from easy_ViTPose.vit_utils.inference import NumpyEncoder, VideoReader\n",
        "# from easy_ViTPose.inference import VitInference\n",
        "# from easy_ViTPose.vit_utils.visualization import joints_dict\n",
        "# import tqdm\n",
        "# import time\n",
        "# from datetime import datetime\n",
        "# from scipy.signal import savgol_filter  # Savitzky-Golay filter for smoothing\n",
        "\n",
        "\n",
        "# model.reset()\n",
        "\n",
        "# reader = VideoReader(video_path)\n",
        "\n",
        "# cap = cv2.VideoCapture(video_path)\n",
        "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "# total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "# cap.release()\n",
        "\n",
        "# if prepare_output_video:\n",
        "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4\n",
        "#     out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# # Process the video frame by frame\n",
        "# keypoints_data = []\n",
        "# fps_list = []\n",
        "# tot_time = 0.0\n",
        "# print(\"Total frames in video:\", total_frames)\n",
        "\n",
        "# for (ith, img) in tqdm.tqdm(enumerate(reader), total=total_frames):\n",
        "#     t0 = time.time()\n",
        "\n",
        "#     if img is None:\n",
        "#         print(f\"Frame {ith} is None, skipping.\")\n",
        "#         continue\n",
        "\n",
        "#     frame_keypoints = model.inference(img)\n",
        "#     keypoints_data.append({'frame': ith, 'keypoints': frame_keypoints})\n",
        "\n",
        "#     delta = time.time() - t0\n",
        "#     tot_time += delta\n",
        "#     fps_list.append(delta)\n",
        "\n",
        "#     if prepare_output_video:\n",
        "#         img_with_keypoints = model.draw(show_yolo=True)[..., ::-1]  # Convert to BGR for OpenCV\n",
        "#         out.write(img_with_keypoints)\n",
        "\n",
        "# if prepare_output_video:\n",
        "#     out.release()\n",
        "# cv2.destroyAllWindows()\n",
        "\n",
        "# # Display the first frame of the processed video as a demonstration\n",
        "# if SHOW_FRAMES:\n",
        "#     cap = cv2.VideoCapture(output_video_path)\n",
        "#     ret, frame = cap.read()\n",
        "#     if ret:\n",
        "#         cv2_imshow(frame)\n",
        "#     cap.release()\n",
        "\n",
        "# # Save the keypoints to a JSON file if required\n",
        "# if output_json_labels:\n",
        "#     skeleton = joints_dict()[model.dataset]['keypoints']\n",
        "#     output_data = create_json_output_format(keypoints_data, skeleton, width, height, fps)\n",
        "\n",
        "#     with open(output_json_path, 'w') as f:\n",
        "#         json.dump(output_data, f, cls=NumpyEncoder)\n",
        "\n",
        "# # Output performance statistics\n",
        "# tot_poses = sum(len(k['keypoints']) for k in keypoints_data)\n",
        "# print(f'Mean inference FPS: {1 / np.mean(fps_list):.2f}')\n",
        "# print(f'Total poses predicted: {tot_poses}, mean per frame: {(tot_poses / len(keypoints_data)):.2f}')\n",
        "# print(f'Mean FPS per pose: {(tot_poses / tot_time):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmetyGey13nR"
      },
      "source": [
        "Quick single file run (no output video)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnvVT-RZ0G44"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import cv2\n",
        "# import json\n",
        "# from easy_ViTPose.vit_utils.inference import NumpyEncoder, VideoReader\n",
        "# from easy_ViTPose.inference import VitInference\n",
        "# import tqdm\n",
        "# import time\n",
        "\n",
        "# # Initialize the video reader\n",
        "# reader = VideoReader(video_path)\n",
        "\n",
        "# # Get video properties\n",
        "# cap = cv2.VideoCapture(video_path)\n",
        "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "# total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "# cap.release()\n",
        "\n",
        "# # Process the video frame by frame\n",
        "# fps_list = []\n",
        "# tot_time = 0.0\n",
        "# print(\"Total frames in video:\", total_frames)\n",
        "\n",
        "# for ith, img in tqdm.tqdm(enumerate(reader), total=total_frames):\n",
        "#     t0 = time.time()\n",
        "\n",
        "#     if img is None:\n",
        "#         print(f\"Frame {ith} is None, skipping.\")\n",
        "#         continue\n",
        "\n",
        "#     # Perform inference\n",
        "#     model.inference(img)\n",
        "\n",
        "#     delta = time.time() - t0\n",
        "#     tot_time += delta\n",
        "#     fps_list.append(delta)\n",
        "\n",
        "# # Output performance statistics\n",
        "# print(f'\\nMean inference FPS: {1 / np.mean(fps_list):.2f}')\n",
        "# print(f'Total inference time: {tot_time:.2f} seconds')\n",
        "# print(f'Total poses predicted: {tot_poses}, mean per frame: {(tot_poses / len(keypoints_data)):.2f}')\n",
        "# print(f'Total frames processed: {len(fps_list)}')\n",
        "# print(f'Mean FPS per pose: {(tot_poses / tot_time):.2f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMzDfT6XbItzRtrA0kOaHbk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}